{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCF2QlTV4Y20"
      },
      "source": [
        "# Excercise 5\n",
        "## NLP with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljZqzxHl4Y21"
      },
      "source": [
        "Use keras framework to solve the below exercises.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yq6_11pU4Y22"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Predict rating of a movie using Keras\n",
        "\n",
        "**Exercise:** Use keras framework to predict rating."
      ],
      "metadata": {
        "id": "8UMYfF4NLvew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataTraining = pd.read_csv('https://github.com/sergiomora03/AdvancedTopicsAnalytics/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)"
      ],
      "metadata": {
        "id": "FIe7VrCjLwQP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataTraining.info()"
      ],
      "metadata": {
        "id": "z0cleJuMrdGc",
        "outputId": "25de7202-a81c-46f9-8d23-d2f925acb3a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 7895 entries, 3107 to 215\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   year    7895 non-null   int64  \n",
            " 1   title   7895 non-null   object \n",
            " 2   plot    7895 non-null   object \n",
            " 3   genres  7895 non-null   object \n",
            " 4   rating  7895 non-null   float64\n",
            "dtypes: float64(1), int64(1), object(3)\n",
            "memory usage: 370.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plots = dataTraining['plot']\n",
        "y = (dataTraining['rating'] >= dataTraining['rating'].mean()).astype(int)"
      ],
      "metadata": {
        "id": "SmFuLoESMvmd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plots"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "5P3fPElaMyPI",
        "outputId": "f1e82b73-69c3-4bdd-91ac-10ec0237ab71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3107    most is the story of a single father who takes...\n",
              "900     a serial killer decides to teach the secrets o...\n",
              "6724    in sweden ,  a female blackmailer with a disfi...\n",
              "4704    in a friday afternoon in new york ,  the presi...\n",
              "2582    in los angeles ,  the editor of a publishing h...\n",
              "                              ...                        \n",
              "8417    \" our marriage ,  their wedding .  \"  it ' s l...\n",
              "1592    the wandering barbarian ,  conan ,  alongside ...\n",
              "1723    like a tale spun by scheherazade ,  kismet fol...\n",
              "7605    mrs .  brisby ,  a widowed mouse ,  lives in a...\n",
              "215     tinker bell journey far north of never land to...\n",
              "Name: plot, Length: 7895, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>plot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3107</th>\n",
              "      <td>most is the story of a single father who takes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>900</th>\n",
              "      <td>a serial killer decides to teach the secrets o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6724</th>\n",
              "      <td>in sweden ,  a female blackmailer with a disfi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4704</th>\n",
              "      <td>in a friday afternoon in new york ,  the presi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2582</th>\n",
              "      <td>in los angeles ,  the editor of a publishing h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8417</th>\n",
              "      <td>\" our marriage ,  their wedding .  \"  it ' s l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1592</th>\n",
              "      <td>the wandering barbarian ,  conan ,  alongside ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1723</th>\n",
              "      <td>like a tale spun by scheherazade ,  kismet fol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7605</th>\n",
              "      <td>mrs .  brisby ,  a widowed mouse ,  lives in a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>tinker bell journey far north of never land to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7895 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "hAUPXQ2eMz47",
        "outputId": "a3ee4fbd-8018-4284-d261-b2be586349b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3107    1\n",
              "900     0\n",
              "6724    1\n",
              "4704    1\n",
              "2582    1\n",
              "       ..\n",
              "8417    0\n",
              "1592    0\n",
              "1723    0\n",
              "7605    1\n",
              "215     1\n",
              "Name: rating, Length: 7895, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3107</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>900</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6724</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4704</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2582</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8417</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1592</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1723</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7605</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7895 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Precosessing\n",
        "\n",
        "- Remove stopwords\n",
        "- Lowercase\n",
        "- split the text in words\n",
        "- pad_sequences"
      ],
      "metadata": {
        "id": "gDHYLQghM9xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Cargar los datos\n",
        "dataTraining = pd.read_csv('https://github.com/sergiomora03/AdvancedTopicsAnalytics/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
        "\n",
        "# Preprocesamiento\n",
        "def preprocess_text(text):\n",
        "    # Convertir a minúsculas\n",
        "    text = text.lower()\n",
        "    # Eliminar puntuaciones y números\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Eliminar stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Aplicar el procesamiento al plot\n",
        "dataTraining['processed_plot'] = dataTraining['plot'].apply(preprocess_text)\n",
        "\n",
        "# Obtener X e y\n",
        "X = dataTraining['processed_plot']\n",
        "y = (dataTraining['rating'] >= dataTraining['rating'].mean()).astype(int)\n",
        "\n",
        "# Dividir el conjunto de datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenización\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding de las secuencias\n",
        "max_length = max(len(seq) for seq in X_train_seq)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length)\n"
      ],
      "metadata": {
        "id": "3pp9N4hDNQK5",
        "outputId": "cdfdb31f-e49b-42da-e5dd-7439db245a55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2iVc1-GNSi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model\n",
        "\n",
        "Create a neural network to predict the rating of a movie, calculate the testing set accuracy."
      ],
      "metadata": {
        "id": "IVQrmkfCNTDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "JuWtGNMUNjtT",
        "outputId": "72ed8c18-801e-4787-b974-674039afcf5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 2s/step - accuracy: 0.5284 - loss: 0.6871 - val_accuracy: 0.6187 - val_loss: 0.6501\n",
            "Epoch 2/5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 2s/step - accuracy: 0.8258 - loss: 0.4080 - val_accuracy: 0.6155 - val_loss: 0.7433\n",
            "Epoch 3/5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 2s/step - accuracy: 0.9686 - loss: 0.1000 - val_accuracy: 0.6084 - val_loss: 1.1655\n",
            "Epoch 4/5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 2s/step - accuracy: 0.9934 - loss: 0.0283 - val_accuracy: 0.6123 - val_loss: 1.6025\n",
            "Epoch 5/5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 2s/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.6116 - val_loss: 2.1472\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 570ms/step - accuracy: 0.5759 - loss: 2.3447\n",
            "Accuracy: 0.5826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy tensorflow nltk\n"
      ],
      "metadata": {
        "id": "HOudNzFoHaHl",
        "outputId": "05fb7e02-840a-4c28-faf7-9debff6a3bcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Descargar stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Cargar los datos\n",
        "dataTraining = pd.read_csv('https://github.com/sergiomora03/AdvancedTopicsAnalytics/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
        "\n",
        "# Preprocesar el texto\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convertir a minúsculas\n",
        "    words = text.split()  # Dividir en palabras\n",
        "    words = [word for word in words if word not in stop_words]  # Eliminar stopwords\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Aplicar el preprocesamiento\n",
        "dataTraining['processed_plot'] = dataTraining['plot'].apply(preprocess_text)\n",
        "\n",
        "# Tokenización\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(dataTraining['processed_plot'])\n",
        "sequences = tokenizer.texts_to_sequences(dataTraining['processed_plot'])\n",
        "\n",
        "# Pad sequences\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Preparar la variable dependiente\n",
        "y = (dataTraining['rating'] >= dataTraining['rating'].mean()).astype(int)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Crear la red neuronal\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_length))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Usar sigmoid para clasificación binaria\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Accuracy en el conjunto de prueba: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "W86wLPkjHc1t",
        "outputId": "741ea30a-b722-40d0-b5ed-7b5fcfc01c87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 694ms/step - accuracy: 0.4941 - loss: 0.6945 - val_accuracy: 0.5435 - val_loss: 0.6901\n",
            "Epoch 2/5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 708ms/step - accuracy: 0.5222 - loss: 0.6929 - val_accuracy: 0.5435 - val_loss: 0.6900\n",
            "Epoch 3/5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 701ms/step - accuracy: 0.5326 - loss: 0.6912 - val_accuracy: 0.5435 - val_loss: 0.6920\n",
            "Epoch 4/5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 697ms/step - accuracy: 0.5097 - loss: 0.6929 - val_accuracy: 0.5435 - val_loss: 0.6905\n",
            "Epoch 5/5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 708ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.5435 - val_loss: 0.6907\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.5616 - loss: 0.6894\n",
            "Accuracy en el conjunto de prueba: 0.5478\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}